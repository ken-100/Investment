{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import block_diag\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# https://github.com/emoen/Machine-Learning-for-Asset-Managers/blob/577f951c8aeb3b478118c3aa30f341be9f8ee09d/Machine_Learning_for_Asset_Managers/ch2_monte_carlo_experiment.py#L15\n",
    "# https://github.com/emoen/Machine-Learning-for-Asset-Managers/blob/577f951c8aeb3b478118c3aa30f341be9f8ee09d/Machine_Learning_for_Asset_Managers/ch7_portfolio_construction.py#L55\n",
    "# https://github.com/emoen/Machine-Learning-for-Asset-Managers/blob/577f951c8aeb3b478118c3aa30f341be9f8ee09d/Machine_Learning_for_Asset_Managers/ch7_portfolio_construction.py#L87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formBlockMatrix(nBlocks, bSize, bCorr):\n",
    "    block = np.ones( (bSize, bSize))*bCorr\n",
    "    block[range(bSize), range(bSize)] = 1 #diagonal is 1\n",
    "    corr = block_diag(*([block]*nBlocks))\n",
    "    return corr\n",
    "\n",
    "def formTrueMatrix(nBlocks, bSize, bCorr):\n",
    "    corr0 = formBlockMatrix(nBlocks, bSize, bCorr)\n",
    "    corr0 = pd.DataFrame(corr0)\n",
    "    cols = corr0.columns.tolist()\n",
    "    np.random.shuffle(cols)\n",
    "    corr0 = corr0[cols].loc[cols].copy(deep=True)\n",
    "    std0 = np.random.uniform(.05, .2, corr0.shape[0])\n",
    "    cov0 = corr2cov(corr0, std0)\n",
    "    mu0 = np.random.normal(std0, std0, cov0.shape[0]).reshape(-1,1)\n",
    "    return mu0, cov0\n",
    "\n",
    "def corr2cov(corr, std):\n",
    "    cov = corr * np.outer(std, std)\n",
    "    return cov\n",
    "\n",
    "def cov2corr(cov):\n",
    "    # Derive the correlation matrix from a covariance matrix\n",
    "    std = np.sqrt(np.diag(cov))\n",
    "    corr = cov/np.outer(std,std)\n",
    "    corr[corr<-1], corr[corr>1] = -1,1 #for numerical errors\n",
    "    return corr\n",
    "\n",
    "def deNoiseCov(cov0, q, bWidth):\n",
    "    corr0 = cov2corr(cov0)\n",
    "    eVal0, eVec0 = getPCA(corr0)\n",
    "    eMax0, var0 = findMaxEval(np.diag(eVal0), q, bWidth)\n",
    "    nFacts0 = eVal0.shape[0]-np.diag(eVal0)[::-1].searchsorted(eMax0)\n",
    "    corr1 = denoisedCorr(eVal0, eVec0, nFacts0) #denoising by constant residual eigenvalue method\n",
    "    cov1 = corr2cov(corr1, np.diag(cov0)**.5)\n",
    "    return cov1\n",
    "\n",
    "def getPCA(matrix):\n",
    "    # Get eVal, eVec from a Hermitian matrix\n",
    "    eVal, eVec = np.linalg.eig(matrix) #complex Hermitian (conjugate symmetric) or a real symmetric matrix.\n",
    "    indices = eVal.argsort()[::-1] #arguments for sorting eval desc\n",
    "    eVal,eVec = eVal[indices],eVec[:,indices]\n",
    "    eVal = np.diagflat(eVal) # identity matrix with eigenvalues as diagonal\n",
    "    return eVal,eVec\n",
    "\n",
    "def findMaxEval(eVal, q, bWidth):\n",
    "    out = minimize(lambda *x: errPDFs(*x), x0=np.array(0.5), args=(eVal, q, bWidth), bounds=((1E-5, 1-1E-5),))\n",
    "#     print(\"found errPDFs\"+str(out['x'][0]))\n",
    "    if out['success']: var = out['x'][0]\n",
    "    else: var=1\n",
    "    eMax = var*(1+(1./q)**.5)**2\n",
    "    return eMax, var\n",
    "\n",
    "\n",
    "def errPDFs(var, eVal, q, bWidth, pts=1000):\n",
    "    var = var[0]\n",
    "    pdf0 = mpPDF(var, q, pts) #theoretical pdf\n",
    "    pdf1 = fitKDE(eVal, bWidth, x=pdf0.index.values) #empirical pdf\n",
    "    sse = np.sum((pdf1-pdf0)**2)\n",
    "#     print(\"sse:\"+str(sse))\n",
    "    return sse\n",
    "\n",
    "def mpPDF(var, q, pts):\n",
    "    eMin, eMax = var*(1-(1./q)**.5)**2, var*(1+(1./q)**.5)**2 # calc lambda_minus, lambda_plus\n",
    "    eVal = np.linspace(eMin, eMax, pts) #Return evenly spaced numbers over a specified interval. eVal='lambda'\n",
    "    #Note: 1.0/2*2 = 1.0 not 0.25=1.0/(2*2)\n",
    "    pdf = q/(2*np.pi*var*eVal)*((eMax-eVal)*(eVal-eMin))**.5 #np.allclose(np.flip((eMax-eVal)), (eVal-eMin))==True\n",
    "    pdf = pd.Series(pdf, index=eVal)\n",
    "    return pdf\n",
    "\n",
    "def fitKDE(obs, bWidth=.15, kernel='gaussian', x=None):\n",
    "    #Fit kernel to a series of obs, and derive the prob of obs\n",
    "    # x is the array of values on which the fit KDE will be evaluated\n",
    "    #print(len(obs.shape) == 1)\n",
    "    if len(obs.shape) == 1: obs = obs.reshape(-1,1)\n",
    "    kde = KernelDensity(kernel = kernel, bandwidth = bWidth).fit(obs)\n",
    "    #print(x is None)\n",
    "    if x is None: x = np.unique(obs).reshape(-1,1)\n",
    "    #print(len(x.shape))\n",
    "    if len(x.shape) == 1: x = x.reshape(-1,1)\n",
    "    logProb = kde.score_samples(x) # log(density)\n",
    "    pdf = pd.Series(np.exp(logProb), index=x.flatten())\n",
    "    return pdf\n",
    "\n",
    "def denoisedCorr(eVal, eVec, nFacts):\n",
    "    eVal_ = np.diag(eVal).copy()\n",
    "    eVal_[nFacts:] = eVal_[nFacts:].sum()/float(eVal_.shape[0] - nFacts) #all but 0..i values equals (1/N-i)sum(eVal_[i..N]))\n",
    "    eVal_ = np.diag(eVal_) #square matrix with eigenvalues as diagonal: eVal_.I\n",
    "    corr1 = (eVec @ eVal_).dot(eVec.T) #Eigendecomposition of a symmetric matrix: S = QÎ›QT\n",
    "    corr1 = cov2corr(corr1) # Rescaling the correlation matrix to have 1s on the main diagonal\n",
    "    return corr1\n",
    "\n",
    "def clusterKMeansBase(corr0, maxNumClusters=10, n_init=10, debug=False):\n",
    "    corr0[corr0 > 1] = 1\n",
    "    dist_matrix = ((1-corr0.fillna(0))/2.)**.5\n",
    "    silh_coef_optimal = pd.Series(dtype='float64') #observations matrixs\n",
    "    kmeans, stat = None, None\n",
    "    maxNumClusters = min(maxNumClusters, int(np.floor(dist_matrix.shape[0]/2)))\n",
    "#     print(\"maxNumClusters\"+str(maxNumClusters))\n",
    "    for init in range(0, n_init):\n",
    "    #The [outer] loop repeats the first loop multiple times, thereby obtaining different initializations. Ref: de Prado and Lewis (2018)\n",
    "    #DETECTION OF FALSE INVESTMENT STRATEGIES USING UNSUPERVISED LEARNING METHODS\n",
    "        for num_clusters in range(2, maxNumClusters+1):\n",
    "            #(maxNumClusters + 2 - num_clusters) # go in reverse order to view more sub-optimal solutions\n",
    "            kmeans_ = KMeans(n_clusters=num_clusters, n_init=10) #, random_state=3425) #n_jobs=None #n_jobs=None - use all CPUs\n",
    "            kmeans_ = kmeans_.fit(dist_matrix)\n",
    "            silh_coef = silhouette_samples(dist_matrix, kmeans_.labels_)\n",
    "            stat = (silh_coef.mean()/silh_coef.std(), silh_coef_optimal.mean()/silh_coef_optimal.std())\n",
    "\n",
    "            # If this metric better than the previous set as the optimal number of clusters\n",
    "            if np.isnan(stat[1]) or stat[0] > stat[1]:\n",
    "                silh_coef_optimal = silh_coef\n",
    "                kmeans = kmeans_\n",
    "                if debug==True:\n",
    "                    print(kmeans)\n",
    "                    print(stat)\n",
    "                    silhouette_avg = silhouette_score(dist_matrix, kmeans_.labels_)\n",
    "                    print(\"For n_clusters =\"+ str(num_clusters)+ \"The average silhouette_score is :\"+ str(silhouette_avg))\n",
    "                    print(\"********\")\n",
    "    \n",
    "    newIdx = np.argsort(kmeans.labels_)\n",
    "    #print(newIdx)\n",
    "\n",
    "    corr1 = corr0.iloc[newIdx] #reorder rows\n",
    "    corr1 = corr1.iloc[:, newIdx] #reorder columns\n",
    "\n",
    "    clstrs = {i:corr0.columns[np.where(kmeans.labels_==i)[0]].tolist() for i in np.unique(kmeans.labels_)} #cluster members\n",
    "    silh_coef_optimal = pd.Series(silh_coef_optimal, index=dist_matrix.index)\n",
    "    \n",
    "    return corr1, clstrs, silh_coef_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code snippet 7.1 - Composition of block-diagonal correlation matric\n",
    "corr0 = formBlockMatrix(2, 2, .5)\n",
    "eVal, eVec = np.linalg.eigh(corr0)\n",
    "print = max(eVal)/min(eVal)\n",
    "sns.heatmap(corr0, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code snippet 7.2 - block-diagonal correlation matrix with a dominant block\n",
    "corr0 = block_diag(formBlockMatrix(1,2, .5))\n",
    "corr1 = formBlockMatrix(1,2, .0)\n",
    "corr0 = block_diag(corr0, corr1)\n",
    "eVal, eVec = np.linalg.eigh(corr0)\n",
    "max(eVal) / min(eVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet 7.3 - NCO method. Step 1. Correlation matrix clustering\n",
    "# nBlocks, bSize, bCorr = 2, 2, .5\n",
    "# q = 10.0\n",
    "# np.random.seed(0)\n",
    "# mu0, cov0 = mc.formTrueMatrix(nBlocks, bSize, bCorr)\n",
    "mu0, cov0 = formTrueMatrix(nBlocks, bSize, bCorr)\n",
    "cols = cov0.columns\n",
    "cov1 = deNoiseCov(cov0, q, bWidth=.01) #denoise cov\n",
    "cov1 = pd.DataFrame(cov1, index=cols, columns=cols)\n",
    "corr1 = cov2corr(cov1)\n",
    "corr1, clstrs, silh = clusterKMeansBase(pd.DataFrame(corr0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minVarPort(cov):\n",
    "    return optPort(cov, mu = None)\n",
    "\n",
    "def optPort(cov, mu = None):\n",
    "    inv = np.linalg.inv(cov) #The precision matrix: contains information about the partial correlation between variables,\n",
    "    #  the covariance between pairs i and j, conditioned on all other variables (https://www.mn.uio.no/math/english/research/projects/focustat/publications_2/shatthik_barua_master2017.pdf)\n",
    "    ones = np.ones(shape = (inv.shape[0], 1)) # column vector 1's\n",
    "    if mu is None: \n",
    "        mu = ones\n",
    "    w = inv @ mu\n",
    "    w /= ones.T @  w # def: w = w / sum(w) ~ w is column vector\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet 7.4 - intracluster optimal allocations\n",
    "wIntra = pd.DataFrame(0, index=cov0.index, columns=clstrs.keys())\n",
    "for i in clstrs:\n",
    "    wIntra.loc[clstrs[i], i] = minVarPort(cov1.loc[clstrs[i], clstrs[i]]).flatten()\n",
    "\n",
    "cov2 = wIntra.T.dot( cov1 @ wIntra) #reduced covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet 7.5 - intercluster optimal allocations\n",
    "# step 3. compute optimal intercluster allocations, usint the reduced covariance matrix\n",
    "# which is close to a diagonal matrix, so optimization problem is close to ideal case \\ro =0\n",
    "wInter = pd.Series(minVarPort(cov2).flatten(), index=cov2.index)\n",
    "wAll0 = wIntra.mul(wInter, axis=1).sum(axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6\n",
    "def optPort_nco(cov, mu=None, maxNumClusters=None):\n",
    "    cov = pd.DataFrame(cov)\n",
    "    if mu is not None:\n",
    "        mu = pd.Series(mu[:,0])\n",
    "    \n",
    "    corr1 = cov2corr(cov)\n",
    "    \n",
    "    # Optimal partition of clusters (step 1)\n",
    "    corr1, clstrs, _ = clusterKMeansBase(corr1, maxNumClusters, n_init=10)\n",
    "    #wIntra = pd.DataFrame(0, index=cov.index, columns=clstrs.keys())\n",
    "    w_intra_clusters = pd.DataFrame(0, index=cov.index, columns=clstrs.keys())\n",
    "    for i in clstrs:\n",
    "        cov_cluster = cov.loc[clstrs[i], clstrs[i]].values\n",
    "        if mu is None:\n",
    "            mu_cluster = None\n",
    "        else: \n",
    "            mu_cluster = mu.loc[clstrs[i]].values.reshape(-1,1)\n",
    "        \n",
    "        #Long/Short\n",
    "        #w_intra_clusters.loc[clstrs[i],i] = mc.optPort(cov_cluster, mu_cluster).flatten()\n",
    "        \n",
    "        # Long only: Estimating the Convex Optimization Solution in a cluster (step 2)\n",
    "        w_intra_clusters.loc[clstrs[i], i] = allocate_cvo(cov_cluster, mu_cluster).flatten()        \n",
    "    \n",
    "    cov_inter_cluster = w_intra_clusters.T.dot( cov @ w_intra_clusters) #reduce covariance matrix\n",
    "    mu_inter_cluster = (None if mu is None else w_intra_clusters.T.dot(mu))\n",
    "    \n",
    "    #Long/Short\n",
    "    #w_inter_clusters = pd.Series(mc.optPort(cov_inter_cluster, mu_inter_cluster).flatten(), index=cov_inter_cluster.index)\n",
    "    # Long only: Optimal allocations across the reduced covariance matrix (step 3)\n",
    "    w_inter_clusters = pd.Series(allocate_cvo(cov_inter_cluster, mu_inter_cluster).flatten(), index=cov_inter_cluster.index)    \n",
    "    \n",
    "    # Final allocations - dot-product of the intra-cluster and inter-cluster allocations (step 4)\n",
    "    nco = w_intra_clusters.mul(w_inter_clusters, axis=1).sum(axis=1).values.reshape(-1,1)\n",
    "    return nco\n",
    "\n",
    "def allocate_cvo(cov, mu_vec=None):\n",
    "    \"\"\"\n",
    "    Estimates the Convex Optimization Solution (CVO).\n",
    "    Uses the covariance matrix and the mu - optimal solution.\n",
    "    If mu is the vector of expected values from variables, the result will be\n",
    "    a vector of weights with maximum Sharpe ratio.\n",
    "    If mu is a vector of ones, the result will be a vector of weights with\n",
    "    minimum variance.\n",
    "    :param cov: (np.array) Covariance matrix of the variables.\n",
    "    :param mu_vec: (np.array) Expected value of draws from the variables for maximum Sharpe ratio.\n",
    "                          None if outputting the minimum variance portfolio.\n",
    "    :return: (np.array) Weights for optimal allocation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculating the inverse covariance matrix\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    \n",
    "    # Generating a vector of size of the inverted covariance matrix\n",
    "    ones = np.ones(shape=(inv_cov.shape[0], 1))\n",
    "    \n",
    "    if mu_vec is None:  # To output the minimum variance portfolio\n",
    "        mu_vec = ones\n",
    "    \n",
    "    # Calculating the analytical solution using CVO - weights\n",
    "    w_cvo = np.dot(inv_cov, mu_vec)\n",
    "    w_cvo /= np.dot(mu_vec.T, w_cvo)\n",
    "    \n",
    "    return w_cvo    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet 7.7 - data-generating process\n",
    "nBlocks, bSize, bCorr = 10, 50, .5\n",
    "np.random.seed(0)\n",
    "mu0, cov0 = formTrueMatrix(nBlocks, bSize, bCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simCovMu(mu0, cov0, nObs, shrink=False):\n",
    "    x = np.random.multivariate_normal(mu0.flatten(), cov0, size = nObs)\n",
    "    #print(x.shape)\n",
    "    mu1 = x.mean(axis = 0).reshape(-1,1) #calc mean of columns of rand matrix\n",
    "    #print(mu1.shape)\n",
    "    if shrink: cov1 = LedoitWolf().fit(x).covariance_\n",
    "    else: cov1 = np.cov(x, rowvar=0)\n",
    "    return mu1, cov1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet 7.8 - drawing an empirical vector of means and covariance matrix\n",
    "nObs, nSims, shrink, minVarPortf = 1000, 1000, False, True\n",
    "np.random.seed(0)\n",
    "w1 = pd.DataFrame(0, index=range(0, nSims), columns=range(0, nBlocks*bSize))\t\n",
    "w1_d = pd.DataFrame(0, index=range(0, nSims), columns=range(0, nBlocks*bSize))\n",
    "for i in range(0, nSims):\n",
    "    mu1, cov1 = simCovMu(mu0, cov0, nObs, shrink=shrink)\n",
    "    if minVarPortf:\n",
    "        mu1 = None\n",
    "    w1.loc[i] = optPort(cov1, mu1).flatten() #markowitc\n",
    "    w1_d.loc[i] = optPort_nco(cov1, mu1, int(cov1.shape[0]/2)).flatten() #nco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snippet 7.9 - Estimation of allocation errors\n",
    "w0 = mc.optPort(cov0, None if minVarPortf else mu0)\n",
    "w0 = np.repeat(w0.T, w1.shape[0], axis=0) #true allocation\n",
    "rmsd = np.mean((w1-w0).values.flatten()**2)**.5 #RMSE\n",
    "rmsd_d = np.mean((w1_d-w0).values.flatten()**2)**.5 #RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
